{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import GradientBoostedTrees\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "from pyspark.mllib.classification import SVMWithSGD\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "from pyspark.mllib.linalg import Vectors, DenseVector, SparseVector\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "import operator\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"set spark.sql.shuffle.partitions=5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "party_values = [\n",
    "    'end_customer_party_ssot_party_id_int_sav_party_id',\n",
    "    'prior_party_ssot_party_id_int_sav_party_id',\n",
    "    'sol_branch_party',\n",
    "    'sol_gu_party',\n",
    "    'sol_hq_party',\n",
    "    'order_level_branch_party',\n",
    "    'order_level_gu_party',\n",
    "    'order_level_hq_party',\n",
    "    'line_level_branch_party',\n",
    "    'line_level_gu_party',\n",
    "    'line_level_hq_party',\n",
    "    'ship_to_branch_party',\n",
    "    'ship_to_gu_party',\n",
    "    'ship_to_hq_party',\n",
    "    'bill_to_branch_party',\n",
    "    'bill_to_gu_party',\n",
    "    'bill_to_hq_party',\n",
    "    'sold_to_branch_party',\n",
    "    'sold_to_gu_party',\n",
    "    'sold_to_hq_party'\n",
    "]\n",
    "\n",
    "address_fields = [\n",
    "    'address1', 'address2', 'address3', 'address4',\n",
    "    'city', 'county', 'state', 'postal_code', 'street_name',\n",
    "    'street_number', 'street_direction', 'street_type'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savm_parsed = sqlContext.sql(\"select * from ignite.savm_parsed\").repartition(100).cache()\n",
    "#temp because hadoop disk can't keep up...\n",
    "party_expansion = sqlContext.sql(\"select * from ignite.party_expansion_temp\").select(party_values +\n",
    "        [\n",
    "            'id', 'sales_acct_id', 'prior_party_name', 'end_customer_line_fix'\n",
    "        ]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsh_candidates = sqlContext.sql('select * from ignite.lsh_savm_candidates_2').withColumn('candidate_party_id', F.col('party_id_candidate'))\n",
    "direct_candidates = sqlContext.sql('select * from ignite.direct_id_candidates').withColumn('candidate_party_id', F.col('candidate_party'))\n",
    "columns = ['id', 'candidate_sales_acct_id', 'candidate_party_id']\n",
    "candidate_gen = lsh_candidates.select(columns).unionAll(direct_candidates.select(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_modeling_savm = sqlContext.sql('select * from ignite.topic_modeling_savm_tfidf')\n",
    "topic_modeling_words = sqlContext.sql('select * from ignite.topic_modeling_per_word').cache()\n",
    "cr_parsed = sqlContext.sql(\"select * from ignite.cr_parsed\").repartition(500).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# thin out whatever we can\n",
    "def drop_columns(df, columns):\n",
    "    return df.select([c for c in df.columns if c not in columns])\n",
    "\n",
    "savm_parsed = drop_columns(savm_parsed, ['geo_valid_status', 'completenes_status', 'cleansed_status', 'start_date', 'end_date',\n",
    "                          'program_id', 'request_id', 'created_by', 'last_updated_by', 'creation_date', 'last_update_date',\n",
    "                          'certified_date', 'site_expl_id', 'conflict_batch_id', 'sa_member_id', 'parent_sa_member_id',\n",
    "                          'link_party_type', 'account_type', 'operation_type'\n",
    "                    ])\n",
    "cr_parsed = drop_columns(cr_parsed, ['geo_valid_status', 'completenes_status', 'cleansed_status', 'start_date', 'end_date',\n",
    "                          'program_id', 'request_id', 'created_by', 'last_updated_by', 'creation_date', 'last_update_date',\n",
    "                          'certified_date'\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "builder = savm_parsed.fillna(-1, ['party_id', 'parent_party_id'])\n",
    "builder = builder.fillna(\"\", ['address1', 'address2', 'city', 'state', 'postal_code', 'country_code', 'cleaned_name'])\n",
    "\n",
    "columnized_savm = builder.groupby('sales_acct_id').agg(\n",
    "    F.collect_list('party_id').alias('savm_party_ids'),\n",
    "    F.collect_list('parent_party_id').alias('savm_parent_party_ids'),\n",
    "    F.collect_list('address1').alias('savm_address_1'),\n",
    "    F.collect_list('address2').alias('savm_address_2'),\n",
    "    F.collect_list('city').alias('savm_city'),\n",
    "    F.collect_list('state').alias('savm_state'),\n",
    "    F.collect_list('postal_code').alias('savm_postal_code'),\n",
    "    F.collect_list('country_code').alias('savm_country_code'),\n",
    "    F.collect_list('split_pct').alias('savm_split_pct'),\n",
    "    F.collect_list('cleaned_name').alias('savm_cleaned_name'),\n",
    ")\n",
    "\n",
    "def trim_list(x, k = 100):\n",
    "    if len(x) > k:\n",
    "        return x[:k]\n",
    "    return x\n",
    "\n",
    "def select_columns(columnized_savm):\n",
    "    columns = []\n",
    "    for c in columnized_savm.columns:\n",
    "        if c == 'sales_acct_id':\n",
    "            columns.append(F.col('sales_acct_id').alias('savm_sales_acct_id'))\n",
    "        else:\n",
    "            columns.append(c)\n",
    "    return columns\n",
    "\n",
    "def apply_function(df, fields, function):\n",
    "    for field in fields:\n",
    "        df = df.withColumn(field, function(field))\n",
    "    return df\n",
    "\n",
    "columnized_savm = columnized_savm.select(select_columns(columnized_savm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnized_savm = apply_function(columnized_savm, ['savm_party_ids', 'savm_parent_party_ids'], lambda c : F.udf(trim_list, ArrayType(IntegerType()))(F.col(c).cast(ArrayType(IntegerType()))).alias(c))\n",
    "columnized_savm = apply_function(columnized_savm, [\n",
    "        'savm_address_1', 'savm_address_2', 'savm_city', 'savm_state',\n",
    "        'savm_postal_code', 'savm_country_code', \n",
    "        'savm_split_pct', 'savm_cleaned_name'\n",
    "    ], lambda c : F.udf(trim_list, ArrayType(StringType()))(F.col(c)).alias(c))\n",
    "columnized_savm = columnized_savm.repartition(2000, 'savm_sales_acct_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(savm_sales_acct_id=203850076.0, savm_party_ids=[43490895, 232764067, 281649435, 280839189, 231861733, 239847484, 122792312, 250486581, 232935868, 244994938, 234635568, 246804156, 44142969, 233580088, 135492702, 254747825, 245749845, 224895319, 204222472, 247309862, 240752903, 246400438, 158016724, 269138341, 235363178, 138559180, 232137898, 234644335, 87536854, 205029960, 258355630, 234622741, 271361593, 256874456, 233674402, 211815965, 249313159, 280809386, 235868837, 244439617, 185479220, 274273679, 247314251, 281395787, 271741272, 269988782, 247551788, 44701422, 246637068, 170671506, 256242944, 253856154, 255665078, 181209640, 158843395, 43490847, 255079090, 45505862, 235367192, 10795311, 9351509, 270906855, 32084038, 232621400, 228900124, 270703843, 111707483, 115418156, 245839334, 269619617, 256103028, 83671198, 248945881, 275003045, 248324373, 255665465, 238165170, 270841034, 9872712, 84884762, 112372717, 4880293, 232396179, 233522272, 222744242, 257903413, 266389002, 236981639, 236071372, 249715649, 273335975, 207196145, 256831699, 115661478, 256628998, 247386808, 277388066, 255672382, 220204603, 246805443], savm_parent_party_ids=[7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, -1, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692, 7511692], savm_address_1=[u'1566 W ALGONQUIN RD', u'2801 LAKESIDE DR', u'ROCK IS', u'2801 LAKESIDE DR FL 3, DEERFIELD, IL 60015 US', u'2801 LAKESIDE DR', u'33 NW IRVING AVE', u'10379 MONARCH RD', u'801 LAKESIDE FL 1', u'2180 LAKESIDE DR', u'2801 LAKESIDE DR', u'2801 LAKESIDE DR', u'2801 LAKESIDE 1ST FLOOR', u'2301 SHERMER RD', u'2801 LAKESIDE DR', u'DISTI DID NOT PROVIDE ADDRESS LINE1', u'2801 LAKESIDE FL 1', u'6744 INDIAN WAY W', u'4337 S PERRYVILLE RD', u'846 SHAGBARK LN', u'3384 COMMERCIAL AVE', u'2301 LAKESIDE DRIVE', u'2801 LAKESIDE DRSTE 125 ', u'860 REMINGTON RD', u'7301 S MEADE AVE', u'111 BARCLAY BLVD', u'500 LAKE COOK RD', u'2801 LAKESIDE FL 1   LJ 4700 FUSER', u'2801 LAKESIDE DR', u'2775 SHERMER RD', u'4337 S PERRYVILLE RD', u'2801 LAKESIDE FL 1', u'2801 LAKESIDE DR STE 125', u'2801 LAKESIDE FL 1', u'4337 S PERRYVILLE RD STE 107', u'2801 LAKESIDE DR', u'PO BOX 1903', u'2801 LAKESIDE 1ST FLOOR', u'170 W TASMAN DR', u'3911 W ADDISON ST', u'495 W BURGUNDY ST', u'200 N MILWAUKEE AVE', u'2801 LAKESIDE DR', u'2801 LAKESIDE 1ST FLOOR', u'8471 BIG BOY DR NE', u'29 E STEPHENSON ST', u'118 DAVID DR', u'2801 LAKESIDE 1ST FLOOR', u'1102 BEED AVE', u'2801 LAKESIDE FL 1   335466 PHONES', u'2801LAKESIDE', u'4337 S PERRYVILLE RD', u'2801 LAKESIDE DR', u'SUBSCRIBER DID NOT PROVIDE ADDRESS LINE1', u'9300 METCALF AVE', u'9000 W COLLEGE PKWY', u'1566 W ALGONQUIN RD', u'2801 LAKESIDE 1ST FLOOR', u'850 CENTRAL AVE', u'6840 32ND ST', u'100 CHICAGO ST.', u'1211 SANCTUARY LN', u'2801 LAKESIDE FL 1', u'2275 HALF DAY RD', u'2801 LAKESIDE DR', u'4337 S PERRYVILLE RD', u'222 MERCHANDISE MART PLZ', u'ATTN BORISLAV MATEEV', u'540 W FRONTAGE RD', u'4337 S PERRYVILLE RD STE 107', u'1331 E BUSINESS CENTER DR', u'2801 LAKESIDE FL 1', u'1619 VINCENT CT', u'400 N EXECUTIVE DR', u'2801 LAKESIDE DR', u'SUBSCRIBER DID NOT PROVIDE ADDRESS LINE1', u'2801 LAKESIDE DR', u'1350 17TH ST', u'2801 LAKESIDE FL 1', u'13200 NETCALF AVENUE', u'139 MIDDLETOWN AVE', u'1601 W ALGONQUIN RD', u'1502 CENTER ST', u'4337 S PERRYVILLE RD', u'4337 S PERRYVILLE RD', u'4337 S PERRYVILLE RD STE 107', u'2801 LAKESIDE FL 1', u'3384 COMMERCIAL AVE', u'2801 LAKESIDE DR', u'4337 S PERRYVILLE RD STE 107', u'2801 LAKESIDE DR STE 125', u'2801 LAKESIDE DR', u'4337 S PERRYVILLE RD', u'2801 LAKESIDE FL 1', u'570 LAKE COOK RD', u'4337 S PERRYVILLE RD STE 107', u'3384 COMMERCIAL AVE', u'2801 LAKESIDE DRIVE STE 125', u'SUBSCRIBER DID NOT PROVIDE ADDRESS LINE1', u'2801 LAKESIDE DR', u'2801 LAKESIDE 1ST FLOOR'], savm_address_2=[u'', u'STE 125', u'', u'', u'STE 125', u'', u'UNIT 4', u'PO  HUC CISCO B200-GORE  0-GORE', u'', u'PO  CIT20141219H-ERLANGEN BAYERN', u'STE 1', u'TFSB 335466 PHONES', u'', u'STE 1', u'', u'PO  TFSB  TIMONIUM CD 2911', u'', u'STE 107', u'APT 301', u'', u'', u'', u'', u'', u'STE 280', u'STE 280', u'PO  FUJI - HUC SONOSITE PHO', u'STE 1', u'', u'STE 107', u'PO  CISCO 7841 FOR MARON HOSTED X4', u'ATTN MARC CASTIGLIONE', u'PO HUC-GWC SWITCHES JOSE MACIEL', u'PO  7TMCREQ14532 - POWER SUPPLIES', u'', u'', u'PO  HUC TFSB 2911X1   TFSB 335092', u'', u'', u'UNIT 932', u'', u'STE 125', u'NCSA 2911 336493', u'', u'', u'', u'PO SERVICEMASTER-HUC', u'', u'PO  TFSB HUC PHONES 8861 8941', u'DR', u'PO  15000551', u'STE 125-HUC', u'', u'', u'', u'UNIT 193', u'PO  FIVE9-ASR-JW', u'', u'', u'', u'', u'PO HUC-GWC SWITCHES', u'STE 300', u'STE 125', u'', u'STE 1212', u'2108 LAKESIDE DR', u'STE 3270', u'PO  153-OAR  1591138O', u'', u'PO  HUC ZORCH-2911-SEC   342636', u'', u'', u'PO CSC115185', u'', u'FL 3', u'STE 200', u'PO PW EMAIL APPROVAL', u'STE 300', u'STE 2', u'', u'STE 102', u'STE 107', u'STE 107', u'PO BOX 3970', u'PO  HUC-GWC SFP S', u'', u'STE 300', u'PO  CIT20141217A', u'PO ASPERALLANEMAIL20150610', u'STE 125', u'STE 107', u'PO  KIRK UCS FOR 2801   DAVE COSTA', u'', u'PO  15000551', u'PO  SIGNED QB EST  4555.1', u'PO CIT20160725D', u'', u'', u'PO ALSIP 3650'], savm_city=[u'HOFFMAN ESTATES', u'DEERFIELD', u'CHICAGO', u'DEERFIELD', u'DEERFIELD', u'BEND', u'ROSCOE', u'DEERFIELD', u'DEERFIELD', u'DEERFIELD', u'DEERFIELD', u'DEERFIELD', u'NORTHBROOK', u'DEERFIELD', u'INDIAN TRAIL ESTATES', u'DEERFIELD', u'MINNEAPOLIS', u'CHERRY VALLEY', u'NORTH AURORA', u'NORTHBROOK', u'DEERFIELD', u'DEERFIELD', u'SCHAUMBURG', u'CHICAGO', u'LINCOLNSHIRE', u'DEERFIELD', u'DEERFIELD', u'DEERFIELD', u'NORTHBROOK', u'CHERRY VALLEY', u'DEERFIELD', u'BANNOCKBURN', u'DEERFIELD', u'CHERRY VALLEY', u'DEERFIELD', u'EVANSTON', u'DEERFIELD', u'SAN JOSE', u'CHICAGO', u'LITTLETON', u'VERNON HILLS', u'DEERFIELD', u'DEERFIELD', u'REMER', u'FREEPORT', u'STREAMWOOD', u'DEERFIELD', u'ELBURN', u'DEERFIELD', u'BROADVIEW', u'CHERRY VALLEY', u'DEERFIELD', u'DEERFIELD', u'OVERLAND PARK', u'PALOS HILLS', u'HOFFMAN ESTATES', u'DEERFIELD', u'HANOVER PARK', u'BERWYN', u'CHICAGO', u'NAPERVILLE', u'DEERFIELD', u'DEERFIELD', u'DEERFIELD', u'CHERRY VALLEY', u'CHICAGO', u'DEERFIELD', u'WINNETKA', u'CHERRY VALLEY', u'MOUNT PROSPECT', u'DEERFIELD', u'NAPERVILLE', u'BROOKFIELD', u'DEERFIELD', u'N/A', u'DEERFIELD', u'DENVER', u'DEERFIELD', u'OVERLAND PARK', u'NORTH HAVEN', u'MOUNT PROSPECT', u'BETHLEHEM', u'CHERRY VALLEY', u'CHERRY VALLEY', u'CHERRY VALLEY', u'DEERFIELD', u'', u'DEERFIELD', u'CHERRY VALLEY', u'DEERFIELD', u'DEERFIELD', u'CHERRY VALLEY', u'DEERFIELD', u'DEERFIELD', u'CHERRY VALLEY', u'NORTHBROOK', u'DEERFIELD', u'DEERFIELD', u'DEERFIELD', u'DEERFIELD'], savm_state=[u'IL', u'IL', u'IL', u'IL', u'IL', u'OR', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'MN', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'CA', u'IL', u'CO', u'IL', u'IL', u'IL', u'MN', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'KS', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'WI', u'IL', u'N/A', u'IL', u'CO', u'IL', u'KS', u'CT', u'IL', u'PA', u'IL', u'IL', u'IL', u'IL', u'', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL', u'IL'], savm_postal_code=[u'60192', u'60015', u'60290', u'60015', u'60015', u'97701', u'61073', u'60015', u'60015', u'60015', u'60015', u'60015', u'60062', u'60015', u'60015', u'60015', u'55439', u'61016', u'60542', u'60062', u'60015', u'60015', u'60173', u'60638', u'60069', u'60015', u'60015', u'60015', u'60062', u'61016', u'60015', u'60015', u'60015', u'61016', u'60015', u'60204', u'60015', u'95134', u'60618', u'80129', u'60061', u'60015', u'60015', u'56672', u'61032', u'60107', u'60015', u'60119', u'60015', u'60155', u'61016', u'60015', u'60015', u'66212', u'60465', u'60192', u'60015', u'60133', u'60402', u'34090', u'60540', u'60015', u'60015', u'60015', u'61016', u'60654', u'60015', u'60093', u'61016', u'60056', u'60015', u'60564', u'53005', u'60015', u'', u'60015', u'80202', u'60015', u'66213', u'06473', u'60056', u'18018', u'61016', u'61016', u'61016', u'60015', u'', u'60015', u'61016', u'60015', u'60015', u'61016', u'60015', u'60015', u'61016', u'60062', u'60015', u'60015', u'60015', u'60015'], savm_country_code=[u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US', u'US'], savm_split_pct=[u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0', u'100.0'], savm_cleaned_name=[u'atg', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix', u'netrix llc', u'netrix llc', u'netrix', u'netrix', u'netrix llc', u'netrix', u'netrix', u'netrix', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'u4g', u'netrix llc', u'netrix', u'netrix', u'netrix llc', u'netrix llc', u'netrix', u'u4g netrix', u'netrix', u'netrix llc', u'netrix', u'netrix llc', u'netrix', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix re znhq', u'netrix', u'netrix', u'netrix', u'netrix', u'netrix', u'netrix llc', u'netrix', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'alliance technology group llc', u'netrix', u'netrix atg', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix', u'netrix llc', u'netrix llc', u'netrix', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrixllc', u'netrix llc', u'netrix', u'alliance technology group llc', u'netrix llc', u'netrix llc', u'netrix inc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'zurich netrix', u'netrixllc', u'netrix', u'netrix', u'netrix llc', u'netrix llc', u'netrix llc', u'netrix llc', u'netrixllc', u'netrix'])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnized_savm.where(F.col('savm_sales_acct_id') == 203850076.0).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500019"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnized_savm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnized_savm.write.saveAsTable('ignite.temp_columnized_savm', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columnized_savm = sqlContext.sql('select * from ignite.temp_columnized_savm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_topic_modeling_words = topic_modeling_words.collect()\n",
    "topic_modeling_dict = {}\n",
    "for row in local_topic_modeling_words:\n",
    "    topic_modeling_dict[row.word] = row\n",
    "    \n",
    "topic_modeling_words_broadcast = sc.broadcast(topic_modeling_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(index=333, norm_max=0.19117041108616217, min_tfidf=3.9981968494108535e-05, avg_tfidf=0.6507507212780906, max_tfidf=4.069136284938971, count_docs=403, word=u'orange')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_modeling_words_broadcast.value['orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tf_reduction(row):\n",
    "    threshold = len(row.words) / 100\n",
    "    word_indices = []\n",
    "    tf = []\n",
    "    idf = []\n",
    "    normalized_tfidf = []\n",
    "    for index in range(len(row.tf.indices)):\n",
    "        if row.tf.values[index] > threshold:\n",
    "            word_indices.append(int(row.tf.indices[index]))\n",
    "            tf.append(float(row.tf.values[index]))\n",
    "            idf.append(float(row.idf.values[index]))\n",
    "            normalized_tfidf.append(float(row.normalized_tfidf.values[index]))\n",
    "    return row.sales_acct_id, word_indices, tf, idf, normalized_tfidf\n",
    "\n",
    "topic_modeling_reduced = topic_modeling_savm.map(tf_reduction) \\\n",
    "                                .toDF(['candidate_sales_acct_id', 'word_indices', 'tf', 'idf', 'normalized_tfidf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# just tie candidates to contest data (cr parties comes later)\n",
    "contest_data_grouped = candidate_gen.select(['id', 'candidate_sales_acct_id']).drop_duplicates().join(party_expansion, on = 'id').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates_with_cr = candidate_gen.join(cr_parsed, on = F.col('candidate_party_id') == F.col('party_id')).repartition(2000, 'id')\n",
    "candidates_with_cr = candidates_with_cr.fillna(-1, ['party_id', 'parent_party_id'])\n",
    "candidates_with_cr = candidates_with_cr.fillna(\"\", ['address1', 'address2', 'address3', 'address4', 'city', 'state', 'postal_code', 'country_code', 'cleaned_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columnized_cr = candidates_with_cr.groupby('id', 'candidate_sales_acct_id').agg(\n",
    "    F.collect_list('party_id').alias('cr_party_ids'),\n",
    "    F.collect_list('parent_party_id').alias('cr_parent_party_ids'),\n",
    "    F.collect_list('address1').alias('cr_address1'),\n",
    "    F.collect_list('address2').alias('cr_address2'),\n",
    "    F.collect_list('address3').alias('cr_address3'),\n",
    "    F.collect_list('address4').alias('cr_address4'),\n",
    "    F.collect_list('city').alias('cr_city'),\n",
    "    F.collect_list('state').alias('cr_state'),\n",
    "    F.collect_list('postal_code').alias('cr_postal_code'),\n",
    "    F.collect_list('country_code').alias('cr_country_code'),\n",
    "    F.collect_list('cleaned_name').alias('cr_cleaned_name'),\n",
    ")\n",
    "\n",
    "columnized_cr = columnized_cr.repartition(2000).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, candidate_sales_acct_id: double, cr_party_ids: array<double>, cr_parent_party_ids: array<double>, cr_address1: array<string>, cr_address2: array<string>, cr_address3: array<string>, cr_address4: array<string>, cr_city: array<string>, cr_state: array<string>, cr_postal_code: array<string>, cr_country_code: array<string>, cr_cleaned_name: array<string>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnized_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_candidates = columnized_cr.join(contest_data_grouped, on = ['id', 'candidate_sales_acct_id']).cache()\n",
    "joined_candidates = joined_candidates.withColumn('truth_sales_acct_id', F.col('sales_acct_id')).drop('sales_acct_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_sparse(vectors):\n",
    "    values = defaultdict(float) # Dictionary with default value 0.0\n",
    "    # Add values from v1\n",
    "    for v in vectors:\n",
    "        for i in range(v.indices.size):\n",
    "            values[v.indices[i]] += v.values[i]\n",
    "    return Vectors.sparse(vectors[0].size, dict(values))\n",
    "\n",
    "def hstack_sparse(sparse_vectors):\n",
    "    values = {}\n",
    "    index = 0\n",
    "    for vector in sparse_vectors:\n",
    "        for i in range(vector.indices.shape[0]):\n",
    "            values[vector.indices[i] + index] = vector.values[i]\n",
    "        index += vector.size\n",
    "    return Vectors.sparse(index, values)\n",
    "\n",
    "def list_to_sparse(dense):\n",
    "    values = {}\n",
    "    for i, v in enumerate(dense):\n",
    "        values[i] = v\n",
    "    return SparseVector(len(dense), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def jaccard(set1, set2):\n",
    "    union_length = len(set1.union(set2))\n",
    "    if union_length == 0:\n",
    "        return 0\n",
    "    return float(len(set1.intersection(set2))) / union_length\n",
    "\n",
    "def set_tokenize(string):\n",
    "    if string == None:\n",
    "        return []\n",
    "    split = string.lower().replace(\".\", \"\").replace(\"-\", \" \").replace(\",\", \"\").split(\" \")\n",
    "    return set(split)\n",
    "\n",
    "def equality_check(str1, str2):\n",
    "    if str1 == None or str2 == None:\n",
    "        return 0.5\n",
    "    if str1 != str2:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "# credits to wikibooks\n",
    "def longest_common_substring(s1, s2):\n",
    "    m = [[0] * (1 + len(s2)) for i in xrange(1 + len(s1))]\n",
    "    longest, x_longest = 0, 0\n",
    "    for x in xrange(1, 1 + len(s1)):\n",
    "        for y in xrange(1, 1 + len(s2)):\n",
    "            if s1[x - 1] == s2[y - 1]:\n",
    "                m[x][y] = m[x - 1][y - 1] + 1\n",
    "                if m[x][y] > longest:\n",
    "                    longest = m[x][y]\n",
    "                    x_longest = x\n",
    "            else:\n",
    "                m[x][y] = 0\n",
    "    return s1[x_longest - longest: x_longest]\n",
    "\n",
    "def savm_topic_score(cleaned_name, full_row, word_index_mapping):\n",
    "    topic_scores = [Vectors.sparse(8, [0], [0])]\n",
    "    \n",
    "    unseen_words = 0\n",
    "    words_not_in_savm = 0\n",
    "    \n",
    "    tokens = set_tokenize(cleaned_name)\n",
    "    \n",
    "    for token in tokens:\n",
    "            \n",
    "        #idk how to fix the out of bounds error\n",
    "        if token in topic_modeling_words_broadcast.value:\n",
    "            word_data = topic_modeling_words_broadcast.value[token]\n",
    "\n",
    "            if word_data['index'] in full_row.word_indices:\n",
    "                straight_vector_index = word_index_mapping[word_data['index']]\n",
    "                topic_vector = [\n",
    "                    word_data['count_docs'],\n",
    "                    full_row.normalized_tfidf[straight_vector_index],\n",
    "                    full_row.tf[straight_vector_index],\n",
    "                    full_row.idf[straight_vector_index],\n",
    "                    word_data['norm_max'],\n",
    "                    word_data['min_tfidf'],\n",
    "                    word_data['avg_tfidf'],\n",
    "                    word_data['max_tfidf'],\n",
    "                ]\n",
    "                topic_scores.append(list_to_sparse(topic_vector))\n",
    "            else:\n",
    "                words_not_in_savm += 1\n",
    "        else:\n",
    "            unseen_words += 1\n",
    "\n",
    "    if len(topic_scores) > 1:\n",
    "        topic_scores = topic_scores[1:] # remove the placeholder\n",
    "        \n",
    "    scored_vectors = [(topic[0], topic) for topic in topic_scores]\n",
    "    scored_vectors.sort(key = lambda x : x[0])\n",
    "    \n",
    "    final_subvector = hstack_sparse([concat_and_pad_vectors(scored_vectors), list_to_sparse([unseen_words, words_not_in_savm, len(tokens)])])\n",
    "    \n",
    "    return [min([point[0] for point in topic_scores]), final_subvector]\n",
    "\n",
    "def best_string_scores(full_row, k = 5):\n",
    "    jaccard_scores = []\n",
    "    longest_run = 0\n",
    "    longest_string = None\n",
    "    \n",
    "    savm_cleaned_names = full_row.savm_cleaned_name\n",
    "    \n",
    "    party_names = full_row.cr_cleaned_name + [full_row.prior_party_name, full_row.end_customer_line_fix]\n",
    "    \n",
    "    party_name_tokens = [set_tokenize(name) for name in party_names]\n",
    "    savm_party_name_tokens = [set_tokenize(name) for name in savm_cleaned_names]\n",
    "    \n",
    "    for i in range(len(party_names)):\n",
    "        for j in range(len(savm_cleaned_names)):\n",
    "            jaccard_scores.append(jaccard(party_name_tokens[i], savm_party_name_tokens[j]))\n",
    "            #lcs = longest_common_substring(party_names[i], savm_names[j]).strip()\n",
    "            #if len(lcs) > longest_run:\n",
    "            #    longest_run = len(lcs)\n",
    "            #    longest_string = lcs\n",
    "    \n",
    "    if len(jaccard_scores) < k:\n",
    "        jaccard_scores = jaccard_scores + [0] * (k - len(jaccard_scores))\n",
    "    \n",
    "    #return list_to_sparse([jaccard_score, longest_run, len(longest_string.split(\" \"))])\n",
    "    return list_to_sparse(jaccard_scores[:k])\n",
    "\n",
    "def address_similarity_score(full_row):\n",
    "    # really basic stuff\n",
    "    matching_zips = 0\n",
    "    for cr_zip_code in full_row.cr_postal_code:\n",
    "        if cr_zip_code in full_row.savm_postal_code:\n",
    "            matching_zips += 1\n",
    "    \n",
    "    for cr_address_1 in full_row.cr_address_1:\n",
    "        if cr_address_1 in full_row.savm_address_1:\n",
    "            matching_savms += 1\n",
    "    \n",
    "    return list_to_sparse([matching_zips, matching_savms])\n",
    "    # zip code\n",
    "    '''\n",
    "    zip_code_match = [-1] * 5\n",
    "    savm_zip_counter = Counter()\n",
    "    for zip_code in full_row.savm_postal_code:\n",
    "        for zip_index in range(1, len(zip_code)):\n",
    "            savm_zip_counter[zip_index[:zip_index]] += 1\n",
    "    \n",
    "    for zip_code in full_row.cr_postal_code:\n",
    "        for zip_index in range(1, len(zip_code) - 1):\n",
    "            pass\n",
    "    '''\n",
    "            \n",
    "def concat_and_pad_vectors(scored_vectors, k = 10):\n",
    "    empty_vector = Vectors.sparse(len(scored_vectors[0][1]), {})\n",
    "    \n",
    "    combined_pairwise_vectors = []\n",
    "    for i in range(k):\n",
    "        if i < len(scored_vectors):\n",
    "            combined_pairwise_vectors.append(scored_vectors[i][1])\n",
    "        else:\n",
    "            combined_pairwise_vectors.append(empty_vector)\n",
    "    \n",
    "    return hstack_sparse(combined_pairwise_vectors)\n",
    "\n",
    "def unravel_ints(raveled_string):\n",
    "    ints = []\n",
    "    for elem in raveled_string.split(\",\"):\n",
    "        if elem != '':\n",
    "            ints.append(int(elem))\n",
    "        else:\n",
    "            ints.append(None)\n",
    "    return ints\n",
    "\n",
    "def unravel_floats(raveled_string):\n",
    "    floats = []\n",
    "    for elem in raveled_string.split(\",\"):\n",
    "        if elem != '':\n",
    "            floats.append(float(elem))\n",
    "        else:\n",
    "            floats.append(None)\n",
    "    return floats\n",
    "\n",
    "def featurize_pairwise(full_row, k = 10):\n",
    "\n",
    "    savm_parent_party_ids = full_row.savm_parent_party_ids\n",
    "    \n",
    "    savm_parent_party_id_counter = Counter(savm_parent_party_ids)\n",
    "    \n",
    "    party_match_vector = [0] * len(party_values)\n",
    "    hq_party_match_vector = [0] * len(party_values)\n",
    "    for i, party_value in enumerate(party_values):\n",
    "        party_match_vector[i] = 1 if full_row[party_value] in savm_parent_party_ids else 0\n",
    "        for j, key in enumerate(savm_parent_party_id_counter.keys()):\n",
    "            if key == full_row[party_value] and key != None:\n",
    "                hq_party_match_vector[i] = savm_parent_party_id_counter[key]\n",
    "        \n",
    "    party_match_vector = list_to_sparse(party_match_vector)\n",
    "    hq_party_match_vector = list_to_sparse(hq_party_match_vector)\n",
    "    \n",
    "    # cr_i * savm_i\n",
    "    # count the number of candidates that are direct or hq matching\n",
    "    \n",
    "    num_party_match = 0\n",
    "    num_hq_party_match = 0\n",
    "    \n",
    "    savm_party_ids = full_row.savm_party_ids\n",
    "    savm_party_ids_set = set(savm_party_ids)\n",
    "    \n",
    "    for cr_party in full_row.cr_party_ids:\n",
    "        if cr_party in savm_party_ids_set:\n",
    "            num_party_match += 1\n",
    "        if cr_party in savm_parent_party_id_counter.keys():\n",
    "            num_hq_party_match += 1\n",
    "    \n",
    "    cr_savm_party_match_vector = list_to_sparse([num_party_match, num_hq_party_match])\n",
    "    \n",
    "    # cr_i * savm_(all)\n",
    "\n",
    "    word_index_mapping = {}\n",
    "    for i, index in enumerate(full_row.word_indices):\n",
    "        word_index_mapping[index] = i\n",
    "    \n",
    "    scored_party_vectors = []\n",
    "    for cr_party_cleaned_name in full_row.cr_cleaned_name:\n",
    "        scored_party_vectors.append(savm_topic_score(cr_party_cleaned_name, full_row, word_index_mapping))\n",
    "    \n",
    "    scored_party_vectors.sort(key = lambda x : x[0], reverse = True)\n",
    "    scored_party_vectors = concat_and_pad_vectors(scored_party_vectors, k = 10)\n",
    "    \n",
    "    fuzzy_vector = best_string_scores(full_row)\n",
    "    \n",
    "    # cr_(all) * savm_(all)\n",
    "    \n",
    "    address_vector = address_similarity_score(full_row)\n",
    "    \n",
    "    other_features = list_to_sparse([\n",
    "        len(full_row.cr_party_ids),\n",
    "        len(savm_party_ids)\n",
    "    ])\n",
    "\n",
    "    final_vector_stack = hstack_sparse([\n",
    "            party_match_vector,\n",
    "            hq_party_match_vector,\n",
    "            cr_savm_party_match_vector,\n",
    "            fuzzy_vector,\n",
    "            scored_party_vectors,\n",
    "            address_vector,\n",
    "            other_features\n",
    "        ])\n",
    "    \n",
    "    return (full_row.id, full_row.candidate_sales_acct_id, full_row.truth_sales_acct_id, final_vector_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = joined_candidates.sample(False, 0.01).repartition(1000).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job 6 cancelled because Stage 7 was cancelled\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1370)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply$mcVI$sp(DAGScheduler.scala:1358)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1357)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1357)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofInt.foreach(ArrayOps.scala:156)\n\tat org.apache.spark.scheduler.DAGScheduler.handleStageCancellation(DAGScheduler.scala:1357)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1613)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-dc618e730a4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturize_pairwise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/mapr/spark/spark-1.6.1/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcount\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m         \"\"\"\n\u001b[1;32m-> 1004\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/mapr/spark/spark-1.6.1/python/pyspark/rdd.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    993\u001b[0m         \u001b[1;36m6.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m         \"\"\"\n\u001b[1;32m--> 995\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/mapr/spark/spark-1.6.1/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mfold\u001b[1;34m(self, zeroValue, op)\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;31m# zeroValue provided to each partition is unique from the one provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;31m# to the final reduce call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 869\u001b[1;33m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/mapr/spark/spark-1.6.1/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \"\"\"\n\u001b[0;32m    770\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/mapr/spark/spark-1.6.1/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[1;32m--> 813\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/mapr/spark/spark-1.6.1/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/mapr/spark/spark-1.6.1/python/lib/py4j-0.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    306\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    307\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    309\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job 6 cancelled because Stage 7 was cancelled\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1370)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply$mcVI$sp(DAGScheduler.scala:1358)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1357)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1357)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofInt.foreach(ArrayOps.scala:156)\n\tat org.apache.spark.scheduler.DAGScheduler.handleStageCancellation(DAGScheduler.scala:1357)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1613)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "sample.map(featurize_pairwise).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_joined = sample.join(topic_modeling_reduced, on = 'candidate_sales_acct_id').repartition(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170770"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_joined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featured_pairs = sample_joined.map(featurize_pairwise).cache()#.toDF(['id', 'candidate_sales_acct_id', 'feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_joined = joined_candidates.join(topic_modeling_reduced, on = 'candidate_sales_acct_id')\n",
    "full_joined = full_joined.join(columnized_savm, on = F.col('candidate_sales_acct_id') == F.col('savm_sales_acct_id')).repartition(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# forcing disk resolves some memory issues\n",
    "full_joined.write.saveAsTable('ignite.temp_final_step', mode = 'overwrite')\n",
    "#final_step = sqlContext.sql('select * from ignite.temp_final_step_direct_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_step = sqlContext.sql('select * from ignite.temp_final_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featured_pairs = final_step.map(featurize_pairwise).toDF(['id', 'candidate_sales_acct_id', 'truth_sales_acct_id', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featured_pairs.write.saveAsTable('ignite.training_set_direct_lsh', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = sqlContext.sql(\"select * from ignite.training_set_direct_lsh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_step.where(F.col('id') == 42949685346).where(F.col('candidate_sales_acct_id') == 203768691.0).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=180388636079, candidate_sales_acct_id=203715470.0, truth_sales_acct_id=203744058.0, features=SparseVector(879, {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.5, 45: 0.0, 46: 0.0, 47: 28.0, 48: 2.6102, 49: 217.0, 50: 2116.8583, 51: 0.3178, 52: 0.0003, 53: 1.5604, 54: 3.2517, 55: 2594.0, 56: 0.5838, 57: 90.0, 58: 473.4955, 59: 0.1007, 60: 0.0001, 61: 0.3026, 62: 2.6305, 127: 0.0, 128: 0.0, 129: 2.0, 877: 1.0, 878: 100.0})),\n",
       " Row(id=42949685346, candidate_sales_acct_id=203768691.0, truth_sales_acct_id=203842177.0, features=SparseVector(879, {0: 0.0, 1: 0.0, 2: 0.0, 3: 1.0, 4: 1.0, 5: 0.0, 6: 1.0, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 0.0, 12: 1.0, 13: 1.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 74.0, 24: 74.0, 25: 0.0, 26: 74.0, 27: 74.0, 28: 0.0, 29: 74.0, 30: 74.0, 31: 0.0, 32: 74.0, 33: 74.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 2.0, 41: 2.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.3333, 47: 35.0, 48: 2.6624, 49: 163.0, 50: 1554.8382, 51: 0.3606, 52: 0.0007, 53: 1.336, 54: 4.0881, 55: 1298.0, 56: 1.3354, 57: 131.0, 58: 779.85, 59: 0.0932, 60: 0.0, 61: 0.5674, 62: 2.6885, 63: 72696.0, 64: 0.4094, 65: 124.0, 66: 239.1151, 67: 0.0104, 68: 0.0001, 69: 0.2881, 70: 0.9511, 127: 0.0, 128: 0.0, 129: 3.0, 130: 35.0, 131: 2.6624, 132: 163.0, 133: 1554.8382, 134: 0.3606, 135: 0.0007, 136: 1.336, 137: 4.0881, 138: 1298.0, 139: 1.3354, 140: 131.0, 141: 779.85, 142: 0.0932, 143: 0.0, 144: 0.5674, 145: 2.6885, 146: 72696.0, 147: 0.4094, 148: 124.0, 149: 239.1151, 150: 0.0104, 151: 0.0001, 152: 0.2881, 153: 0.9511, 210: 0.0, 211: 0.0, 212: 3.0, 877: 2.0, 878: 100.0})),\n",
       " Row(id=171798693843, candidate_sales_acct_id=215394434.0, truth_sales_acct_id=203707713.0, features=SparseVector(879, {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 243.0, 48: 1.2856, 49: 95574.0, 50: 728774.2244, 51: 0.3404, 52: 0.0001, 53: 0.357, 54: 3.8126, 55: 19237.0, 56: 0.2327, 57: 40490.0, 58: 131906.727, 59: 0.0264, 60: 0.0001, 61: 0.3166, 62: 1.5763, 63: 72696.0, 64: 0.0627, 65: 18438.0, 66: 35554.88, 67: 0.0104, 68: 0.0001, 69: 0.2881, 70: 0.9511, 127: 0.0, 128: 0.0, 129: 3.0, 877: 1.0, 878: 100.0})),\n",
       " Row(id=214748383277, candidate_sales_acct_id=203711811.0, truth_sales_acct_id=277682548.0, features=SparseVector(879, {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 1.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 32.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 1.0, 42: 0.25, 43: 0.25, 44: 0.0, 45: 0.25, 46: 0.25, 47: 169.0, 48: 1.3056, 49: 4985.0, 50: 39813.2256, 51: 0.2245, 52: 0.0001, 53: 0.8017, 54: 3.6626, 55: 4579.0, 56: 0.6096, 57: 3961.0, 58: 18588.7714, 59: 0.0466, 60: 0.0, 61: 0.5576, 62: 2.2526, 63: 5828.0, 64: 0.5552, 65: 3803.0, 66: 16930.2054, 67: 0.0438, 68: 0.0001, 69: 0.3968, 70: 1.7807, 71: 19237.0, 72: 0.3845, 73: 3599.0, 74: 11724.6804, 75: 0.0264, 76: 0.0001, 77: 0.3166, 78: 1.5763, 127: 0.0, 128: 0.0, 129: 4.0, 130: 169.0, 131: 1.3056, 132: 4985.0, 133: 39813.2256, 134: 0.2245, 135: 0.0001, 136: 0.8017, 137: 3.6626, 138: 4579.0, 139: 0.6096, 140: 3961.0, 141: 18588.7714, 142: 0.0466, 143: 0.0, 144: 0.5576, 145: 2.2526, 146: 5828.0, 147: 0.5552, 148: 3803.0, 149: 16930.2054, 150: 0.0438, 151: 0.0001, 152: 0.3968, 153: 1.7807, 210: 0.0, 211: 1.0, 212: 4.0, 213: 169.0, 214: 1.3056, 215: 4985.0, 216: 39813.2256, 217: 0.2245, 218: 0.0001, 219: 0.8017, 220: 3.6626, 221: 4579.0, 222: 0.6096, 223: 3961.0, 224: 18588.7714, 225: 0.0466, 226: 0.0, 227: 0.5576, 228: 2.2526, 229: 5828.0, 230: 0.5552, 231: 3803.0, 232: 16930.2054, 233: 0.0438, 234: 0.0001, 235: 0.3968, 236: 1.7807, 293: 0.0, 294: 1.0, 295: 4.0, 296: 169.0, 297: 1.3056, 298: 4985.0, 299: 39813.2256, 300: 0.2245, 301: 0.0001, 302: 0.8017, 303: 3.6626, 304: 4579.0, 305: 0.6096, 306: 3961.0, 307: 18588.7714, 308: 0.0466, 309: 0.0, 310: 0.5576, 311: 2.2526, 312: 5828.0, 313: 0.5552, 314: 3803.0, 315: 16930.2054, 316: 0.0438, 317: 0.0001, 318: 0.3968, 319: 1.7807, 320: 19237.0, 321: 0.3845, 322: 3599.0, 323: 11724.6804, 324: 0.0264, 325: 0.0001, 326: 0.3166, 327: 1.5763, 328: 72696.0, 329: 0.093, 330: 1470.0, 331: 2834.6715, 332: 0.0104, 333: 0.0001, 334: 0.2881, 335: 0.9511, 376: 0.0, 377: 0.0, 378: 5.0, 379: 169.0, 380: 1.3056, 381: 4985.0, 382: 39813.2256, 383: 0.2245, 384: 0.0001, 385: 0.8017, 386: 3.6626, 387: 4579.0, 388: 0.6096, 389: 3961.0, 390: 18588.7714, 391: 0.0466, 392: 0.0, 393: 0.5576, 394: 2.2526, 395: 5828.0, 396: 0.5552, 397: 3803.0, 398: 16930.2054, 399: 0.0438, 400: 0.0001, 401: 0.3968, 402: 1.7807, 403: 19237.0, 404: 0.3845, 405: 3599.0, 406: 11724.6804, 407: 0.0264, 408: 0.0001, 409: 0.3166, 410: 1.5763, 411: 72696.0, 412: 0.093, 413: 1470.0, 414: 2834.6715, 415: 0.0104, 416: 0.0001, 417: 0.2881, 418: 0.9511, 459: 0.0, 460: 0.0, 461: 5.0, 462: 169.0, 463: 1.3056, 464: 4985.0, 465: 39813.2256, 466: 0.2245, 467: 0.0001, 468: 0.8017, 469: 3.6626, 470: 4579.0, 471: 0.6096, 472: 3961.0, 473: 18588.7714, 474: 0.0466, 475: 0.0, 476: 0.5576, 477: 2.2526, 478: 5828.0, 479: 0.5552, 480: 3803.0, 481: 16930.2054, 482: 0.0438, 483: 0.0001, 484: 0.3968, 485: 1.7807, 486: 19237.0, 487: 0.3845, 488: 3599.0, 489: 11724.6804, 490: 0.0264, 491: 0.0001, 492: 0.3166, 493: 1.5763, 494: 72696.0, 495: 0.093, 496: 1470.0, 497: 2834.6715, 498: 0.0104, 499: 0.0001, 500: 0.2881, 501: 0.9511, 542: 0.0, 543: 0.0, 544: 5.0, 545: 169.0, 546: 1.3056, 547: 4985.0, 548: 39813.2256, 549: 0.2245, 550: 0.0001, 551: 0.8017, 552: 3.6626, 553: 4579.0, 554: 0.6096, 555: 3961.0, 556: 18588.7714, 557: 0.0466, 558: 0.0, 559: 0.5576, 560: 2.2526, 561: 5828.0, 562: 0.5552, 563: 3803.0, 564: 16930.2054, 565: 0.0438, 566: 0.0001, 567: 0.3968, 568: 1.7807, 569: 19237.0, 570: 0.3845, 571: 3599.0, 572: 11724.6804, 573: 0.0264, 574: 0.0001, 575: 0.3166, 576: 1.5763, 625: 0.0, 626: 0.0, 627: 4.0, 628: 169.0, 629: 1.3056, 630: 4985.0, 631: 39813.2256, 632: 0.2245, 633: 0.0001, 634: 0.8017, 635: 3.6626, 636: 4579.0, 637: 0.6096, 638: 3961.0, 639: 18588.7714, 640: 0.0466, 641: 0.0, 642: 0.5576, 643: 2.2526, 644: 5828.0, 645: 0.5552, 646: 3803.0, 647: 16930.2054, 648: 0.0438, 649: 0.0001, 650: 0.3968, 651: 1.7807, 652: 19237.0, 653: 0.3845, 654: 3599.0, 655: 11724.6804, 656: 0.0264, 657: 0.0001, 658: 0.3166, 659: 1.5763, 708: 0.0, 709: 0.0, 710: 4.0, 711: 169.0, 712: 1.3056, 713: 4985.0, 714: 39813.2256, 715: 0.2245, 716: 0.0001, 717: 0.8017, 718: 3.6626, 719: 4579.0, 720: 0.6096, 721: 3961.0, 722: 18588.7714, 723: 0.0466, 724: 0.0, 725: 0.5576, 726: 2.2526, 727: 5828.0, 728: 0.5552, 729: 3803.0, 730: 16930.2054, 731: 0.0438, 732: 0.0001, 733: 0.3968, 734: 1.7807, 791: 0.0, 792: 1.0, 793: 4.0, 794: 169.0, 795: 1.3056, 796: 4985.0, 797: 39813.2256, 798: 0.2245, 799: 0.0001, 800: 0.8017, 801: 3.6626, 802: 5828.0, 803: 0.5552, 804: 3803.0, 805: 16930.2054, 806: 0.0438, 807: 0.0001, 808: 0.3968, 809: 1.7807, 810: 19237.0, 811: 0.3845, 812: 3599.0, 813: 11724.6804, 814: 0.0264, 815: 0.0001, 816: 0.3166, 817: 1.5763, 874: 0.0, 875: 1.0, 876: 4.0, 877: 10.0, 878: 100.0})),\n",
       " Row(id=68719489767, candidate_sales_acct_id=203797952.0, truth_sales_acct_id=203778413.0, features=SparseVector(879, {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 1.0, 41: 0.0, 42: 1.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 3.0, 48: 6.3194, 49: 42.0, 50: 492.9166, 51: 0.6478, 52: 3.912, 53: 5.517, 54: 6.3194, 127: 0.0, 128: 0.0, 129: 1.0, 877: 1.0, 878: 45.0}))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.sample(False, 0.00001).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
