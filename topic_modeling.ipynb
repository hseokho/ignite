{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import GradientBoostedTrees\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "from pyspark.mllib.classification import SVMWithSGD\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "from pyspark.mllib.linalg import Vectors, DenseVector, SparseVector, VectorUDT\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.mllib.linalg.distributed import CoordinateMatrix, MatrixEntry\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savm = sqlContext.sql(\"select * from ignite.savm_parsed\").repartition(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = savm.map(lambda x : (x.sales_acct_id, x.tokenized_name)).reduceByKey(lambda x, y : x + y).toDF(['sales_acct_id', 'words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(inputCol = 'words', outputCol = 'tf', vocabSize = 1 << 20).fit(grouped)\n",
    "builder = count_vectorizer.transform(grouped)\n",
    "tfidf = IDF(inputCol=\"tf\", outputCol=\"idf\").fit(builder).transform(builder).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(idf_vector, words):\n",
    "    normalizing_factor = len(words) + 1\n",
    "    values = []\n",
    "    for i in range(len(idf_vector.indices)):\n",
    "        values.append(idf_vector.values[i] / normalizing_factor)\n",
    "    return Vectors.sparse(idf_vector.size, idf_vector.indices, values)\n",
    "\n",
    "def true_idf(tf_vector, idf_vector):\n",
    "    indices = tf_vector.indices\n",
    "    values = []\n",
    "    for i in range(len(indices)):\n",
    "        values.append(idf_vector.values[i] / tf_vector.values[i])\n",
    "    return Vectors.sparse(len(indices), indices, values)\n",
    "\n",
    "normalized_tfidf = tfidf.withColumn('normalized_tfidf', F.udf(normalize, VectorUDT())(F.col('idf'), F.col('words'))).repartition(100).cache()\n",
    "normalized_tfidf = normalized_tfidf.withColumn('true_idf', F.udf(true_idf, VectorUDT())(F.col('tf'), F.col('idf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sales_acct_id=254312596.0, words=[u'trung', u'tam', u'cong', u'nghe', u'thong', u'tin', u'thua', u'thien', u'hue'], tf=SparseVector(480948, {2393: 1.0, 5884: 1.0, 6216: 1.0, 9079: 1.0, 10399: 1.0, 13458: 1.0, 21438: 1.0, 36618: 1.0, 136344: 1.0}), idf=SparseVector(480948, {2393: 6.2787, 5884: 7.7897, 6216: 8.2171, 9079: 8.1808, 10399: 8.079, 13458: 8.4219, 21438: 9.0794, 36618: 9.9443, 136344: 11.513}), normalized_tfidf=SparseVector(480948, {2393: 0.6279, 5884: 0.779, 6216: 0.8217, 9079: 0.8181, 10399: 0.8079, 13458: 0.8422, 21438: 0.9079, 36618: 0.9944, 136344: 1.1513}), true_idf=SparseVector(9, {2393: 6.2787, 5884: 7.7897, 6216: 8.2171, 9079: 8.1808, 10399: 8.079, 13458: 8.4219, 21438: 9.0794, 36618: 9.9443, 136344: 11.513})),\n",
       " Row(sales_acct_id=253403496.0, words=[u'public', u'servants', u'social', u'security', u'agency'], tf=SparseVector(480948, {101: 1.0, 177: 1.0, 192: 1.0, 224: 1.0, 43900: 1.0}), idf=SparseVector(480948, {101: 4.1425, 177: 5.2936, 192: 5.5032, 224: 5.931, 43900: 10.7245}), normalized_tfidf=SparseVector(480948, {101: 0.6904, 177: 0.8823, 192: 0.9172, 224: 0.9885, 43900: 1.7874}), true_idf=SparseVector(5, {101: 4.1425, 177: 5.2936, 192: 5.5032, 224: 5.931, 43900: 10.7245})),\n",
       " Row(sales_acct_id=207643096.0, words=[u'krs', u'computer', u'&', u'buiness', u'school', u'krs', u'computer', u'&', u'business', u'school', u'krs', u'computer', u'&', u'business', u'schools', u'inc', u'krs'], tf=SparseVector(480948, {1: 1.0, 6: 3.0, 14: 2.0, 30: 2.0, 141: 3.0, 202: 1.0, 39377: 4.0, 58105: 1.0}), idf=SparseVector(480948, {1: 1.9283, 6: 8.5566, 14: 9.5986, 30: 4.8238, 141: 15.4675, 202: 4.6371, 39377: 42.55, 58105: 10.4144}), normalized_tfidf=SparseVector(480948, {1: 0.1071, 6: 0.4754, 14: 0.5333, 30: 0.268, 141: 0.8593, 202: 0.2576, 39377: 2.3639, 58105: 0.5786}), true_idf=SparseVector(8, {1: 1.9283, 6: 2.8522, 14: 4.7993, 30: 2.4119, 141: 5.1558, 202: 4.6371, 39377: 10.6375, 58105: 10.4144})),\n",
       " Row(sales_acct_id=253357696.0, words=[u'charleston', u'management', u'center', u'sdn', u'bhd'], tf=SparseVector(480948, {66: 1.0, 67: 1.0, 294: 1.0, 315: 1.0, 1436: 1.0}), idf=SparseVector(480948, {66: 3.6587, 67: 3.9458, 294: 4.9387, 315: 4.9737, 1436: 7.7945}), normalized_tfidf=SparseVector(480948, {66: 0.6098, 67: 0.6576, 294: 0.8231, 315: 0.8289, 1436: 1.2991}), true_idf=SparseVector(5, {66: 3.6587, 67: 3.9458, 294: 4.9387, 315: 4.9737, 1436: 7.7945})),\n",
       " Row(sales_acct_id=283315496.0, words=[u'aristo', u'pharma', u'ltd'], tf=SparseVector(480948, {9: 1.0, 958: 1.0, 53350: 1.0}), idf=SparseVector(480948, {9: 1.6143, 958: 6.6196, 53350: 11.1765}), normalized_tfidf=SparseVector(480948, {9: 0.4036, 958: 1.6549, 53350: 2.7941}), true_idf=SparseVector(3, {9: 1.6143, 958: 6.6196, 53350: 11.1765}))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_tfidf.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_tfidf.write.saveAsTable('ignite.topic_modeling_savm_tfidf', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexed_vocab = sc.parallelize([([v, v], ) for v in count_vectorizer.vocabulary]).toDF(['words']).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(words=[u'at&t', u'at&t'])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_vocab.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(words=[u'at&t', u'at&t'], tf=SparseVector(480948, {0: 2.0})),\n",
       " Row(words=[u'inc', u'inc'], tf=SparseVector(480948, {1: 2.0})),\n",
       " Row(words=[u'corporation', u'corporation'], tf=SparseVector(480948, {2: 2.0})),\n",
       " Row(words=[u'services', u'services'], tf=SparseVector(480948, {3: 2.0})),\n",
       " Row(words=[u'llc', u'llc'], tf=SparseVector(480948, {4: 2.0}))]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.transform(indexed_vocab).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_index(tf_vector):\n",
    "    return tf_vector.indices[0]\n",
    "\n",
    "indexed = count_vectorizer.transform(indexed_vocab).map(lambda x : (x.words[0], int(x.tf.indices[0]))).toDF(['word', 'index']).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5669467095138409"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini(list_of_values):\n",
    "    sorted_list = sorted(list(list_of_values))\n",
    "    height, area = 0, 0\n",
    "    for value in sorted_list:\n",
    "        height += value\n",
    "        area += height - value / 2.\n",
    "    fair_area = height * len(list_of_values) / 2\n",
    "    return (fair_area - area) / fair_area\n",
    "\n",
    "def norm_max(values):\n",
    "    return float(max(values) / np.linalg.norm(values))\n",
    "\n",
    "norm_max([1, 3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_tfidfs(tfidf_vector):\n",
    "    tfidf_pairs = []\n",
    "    for i in range(len(tfidf_vector.indices)):\n",
    "        tfidf_pairs.append((int(tfidf_vector.indices[i]), float(tfidf_vector.values[i])))\n",
    "    return tfidf_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gini_coefficients = normalized_tfidf.flatMap(lambda x : flatten_tfidfs(x.normalized_tfidf)).groupByKey().mapValues(lambda x : norm_max([row for row in x])).toDF(['index', 'norm_max'])\n",
    "normalized_tfidf_per_instance = normalized_tfidf.flatMap(lambda x : flatten_tfidfs(x.normalized_tfidf)).toDF(['index', 'value'])\n",
    "min_instance_tfidf = normalized_tfidf_per_instance.groupby(['index']).agg({'value' : 'min'})\n",
    "avg_instance_tfidf = normalized_tfidf_per_instance.groupby(['index']).agg({'value' : 'avg'})\n",
    "max_instance_tfidf = normalized_tfidf_per_instance.groupby(['index']).agg({'value' : 'max'})\n",
    "count_instance_tfidf = normalized_tfidf_per_instance.groupby(['index']).agg({'value' : 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "builder = gini_coefficients.join(min_instance_tfidf.select(['index', F.col('min(value)').alias('min_tfidf')]), 'index')\n",
    "builder = builder.join(avg_instance_tfidf.select(['index', F.col('avg(value)').alias('avg_tfidf')]), 'index')\n",
    "builder = builder.join(max_instance_tfidf.select(['index', F.col('max(value)').alias('max_tfidf')]), 'index')\n",
    "builder = builder.join(count_instance_tfidf.select(['index', F.col('count(value)').alias('count_docs')]), 'index')\n",
    "per_word_index_stats = builder.join(indexed, 'index').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(index=32, norm_max=0.25742810898080287, min_tfidf=0.00011422164154389107, avg_tfidf=1.1433796711068294, max_tfidf=3.0837341218988197, count_docs=47, word=u'comcast')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_word_index_stats.where(F.col('word') == 'comcast').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "per_word_index_stats.write.saveAsTable('ignite.topic_modeling_per_word', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per_word_index_stats = sqlContext.sql(\"select * from ignite.topic_modeling_per_word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(index=60956, norm_max=0.8944271824028374, min_tfidf=0.0009096348640121267, avg_tfidf=2.9343304654924522, max_tfidf=5.8680545077422295, count_docs=3, word=u'noritz')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_word_index_stats.where(F.col('word') == 'noritz').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sales_acct_id=271403401.0, words=[u'shanghai', u'noritz', u'coltd', u'shanghai', u'noritz', u'company', u'ltd', u'shanghai', u'noritz', u'co', u'ltd.', u'shanghai', u'noritz', u'company', u'ltd'], tf=SparseVector(480948, {9: 2.0, 13: 2.0, 43: 1.0, 68: 1.0, 100: 1.0, 248: 4.0, 60956: 4.0}), idf=SparseVector(480948, {9: 3.2285, 13: 4.0939, 43: 3.2408, 68: 3.9098, 100: 3.4836, 248: 17.3948, 60956: 46.9444}), normalized_tfidf=SparseVector(480948, {9: 0.2018, 13: 0.2559, 43: 0.2026, 68: 0.2444, 100: 0.2177, 248: 1.0872, 60956: 2.934}), true_idf=SparseVector(7, {9: 1.6143, 13: 2.0469, 43: 3.2408, 68: 3.9098, 100: 3.4836, 248: 4.3487, 60956: 11.7361})),\n",
       " Row(sales_acct_id=276965243.0, words=[u'noritz', u'noritz', u'corporation', u'noritz', u'corporation', u'noritz', u'corporation', u'noritz', u'corporation', u'noritz', u'corporation', u'noritz', u'corporation', u'noritz', u'corporation', u'noritz', u'corporation', u'noritz', u'corporation'], tf=SparseVector(480948, {2: 9.0, 60956: 10.0}), idf=SparseVector(480948, {2: 27.3994, 60956: 117.3611}), normalized_tfidf=SparseVector(480948, {2: 1.37, 60956: 5.8681}), true_idf=SparseVector(2, {2: 3.0444, 60956: 11.7361}))]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_tfidf.rdd.filter(lambda x : x.normalized_tfidf[60956] > 1).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
